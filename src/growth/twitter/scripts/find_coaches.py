#!/usr/bin/env python3
"""
Twitter Coach Discovery Tool

Finds and analyzes Agency Coaches on Twitter - users who teach others
how to start/scale marketing agencies (SMMA, cold email, ad agencies).

Features:
- Multi-source discovery: Seed list + keyword search + network analysis
- Smart validation: Bio + content analysis to confirm "coach" status
- Follower filtering: 5,000 - 20,000 followers (micro-influencers in the niche)
- Content ratio check: Ensures >40% of tweets are coaching-related
- Recency filter: Active within last 30 days
- CTA detection: Identifies coaching service offers
- Personalized outreach: Generate custom hooks based on each coach's content
- Data export: JSON + CSV for easy analysis

Usage:
    python find_coaches.py --seeds-only --max-profiles 5
    python find_coaches.py --min-validation high
"""

import sys
import json
import time
import random
import argparse
import yaml
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Set
from dataclasses import dataclass, field, asdict
from urllib.parse import quote

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("Warning: pandas not available. CSV export will be limited.")

project_root = Path(__file__).parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from playwright.sync_api import sync_playwright

sys.stdout.reconfigure(line_buffering=True)

# ============================================================================
# Data Models
# ============================================================================

@dataclass
class TweetData:
    """Individual tweet analysis."""
    tweet_url: str
    content: str
    posted_date: str
    likes: int
    retweets: int
    replies: int
    is_coaching_content: bool = False


@dataclass
class CoachProfile:
    """Complete profile of a potential agency coach."""

    # Basic Info
    handle: str
    name: str
    bio: str
    profile_url: str

    # Metrics
    follower_count: int
    verified: bool
    following_count: int = 0

    # Validation
    validation_score: str = "unknown"  # "high" | "medium" | "low" | "unknown"
    coach_indicators: List[str] = field(default_factory=list)

    # Tier (if known from seed list)
    tier: Optional[str] = None  # "cold_email" | "dtc_ads" | "agency_scale"

    # Content Analysis
    recent_tweets: List[TweetData] = field(default_factory=list)
    avg_engagement_rate: float = 0.0
    posting_frequency: float = 0.0  # tweets per day (estimated)

    # Network Analysis
    engages_with_coaches: bool = False
    coach_engagement_score: int = 0  # Number of coach interactions

    # Outreach
    personalized_hook: Optional[str] = None
    hook_rationale: str = ""

    # Metadata
    discovered_via: str = "unknown"  # "seed" | "search:term" | "network"
    discovered_at: str = field(default_factory=lambda: datetime.now().isoformat())
    last_updated: str = field(default_factory=lambda: datetime.now().isoformat())

    # Follower filter compliance
    passes_follower_filter: bool = True

    def to_dict(self) -> Dict:
        """Serialize to dictionary for JSON export."""
        return {
            "handle": self.handle,
            "name": self.name,
            "bio": self.bio,
            "profile_url": self.profile_url,
            "follower_count": self.follower_count,
            "verified": self.verified,
            "following_count": self.following_count,
            "validation_score": self.validation_score,
            "coach_indicators": self.coach_indicators,
            "tier": self.tier,
            "recent_tweets": [
                {
                    "tweet_url": t.tweet_url,
                    "content": t.content,
                    "posted_date": t.posted_date,
                    "likes": t.likes,
                    "retweets": t.retweets,
                    "replies": t.replies,
                    "is_coaching_content": t.is_coaching_content
                }
                for t in self.recent_tweets
            ],
            "avg_engagement_rate": self.avg_engagement_rate,
            "posting_frequency": self.posting_frequency,
            "engages_with_coaches": self.engages_with_coaches,
            "coach_engagement_score": self.coach_engagement_score,
            "personalized_hook": self.personalized_hook,
            "hook_rationale": self.hook_rationale,
            "discovered_via": self.discovered_via,
            "discovered_at": self.discovered_at,
            "last_updated": self.last_updated,
            "passes_follower_filter": self.passes_follower_filter
        }


# ============================================================================
# Constants
# ============================================================================

# Coach validation keywords
COACH_KEYWORDS = [
    "agency", "coach", "consultant", "SMMA", "scale",
    "clients", "mentor", "helping agencies", "cold email",
    "lead gen", "client acquisition", "facebook ads", "meta ads"
]

COACHING_PATTERNS = [
    "how to", "step by step", "case study", "we helped",
    "my agency", "our clients", "generate leads", "scale to"
]

# Tier mapping for seed coaches
TIER_MAP = {
    # Cold Email & Lead Gen
    "blackhatwizardd": "cold_email",
    "alxberman": "cold_email",
    "andrehaykaljr": "cold_email",
    "coldemailwizard": "cold_email",
    "NickAbraham12": "cold_email",
    "EricNowo": "cold_email",
    "OneJKMolina": "cold_email",

    # DTC & Ad Performance
    "iamshackelford": "dtc_ads",
    "Binghott": "dtc_ads",
    "herrmanndigital": "dtc_ads",
    "ecomchasedimond": "dtc_ads",
    "DenneyDara": "dtc_ads",
    "codyplofker": "dtc_ads",
    "rabahrahil": "dtc_ads",
    "social_savannah": "dtc_ads",

    # General Agency Scaling
    "joelkaplan": "agency_scale",
    "raviabuvala": "agency_scale",
    "Tyson_4D": "agency_scale",
    "jordan_ross_8F": "agency_scale",
    "jacobtuwiner": "agency_scale",
    "wizofecom": "agency_scale",
}

# Theme analysis for hook generation
THEME_KEYWORDS = {
    "cold email": ["cold email", "outreach", "lead gen", "prospecting"],
    "ads": ["facebook ads", "meta ads", "ad spend", "roas", "creative"],
    "scaling": ["scale", "growth", "hiring", "team", "operations"],
    "agency": ["my agency", "our agency", "client work", "retainer"]
}


# ============================================================================
# Utility Functions
# ============================================================================

def random_delay(min_seconds: float = 1.0, max_seconds: float = 3.0):
    """Add random delay to simulate human behavior."""
    time.sleep(random.uniform(min_seconds, max_seconds))


def human_like_scroll(page, direction: str = "down"):
    """Scroll with human-like variation."""
    for _ in range(random.randint(2, 4)):
        distance = random.randint(200, 500)
        if direction == "up":
            distance = -distance
        page.evaluate(f"window.scrollBy(0, {distance})")
        time.sleep(random.uniform(0.1, 0.4))


def parse_follower_count(text: str) -> int:
    """Parse follower count with K/M suffixes."""
    text = text.replace(',', '').replace(' ', '').upper()

    if 'K' in text:
        return int(float(text.replace('K', '')) * 1000)
    elif 'M' in text:
        return int(float(text.replace('M', '')) * 1000000)
    else:
        try:
            return int(text)
        except:
            return 0


def parse_count(text: str) -> int:
    """Parse engagement count with K/M suffixes."""
    return parse_follower_count(text)


def safe_extract_text(element) -> str:
    """Extract text from element with null checks."""
    try:
        return element.inner_text() if element else ""
    except:
        return ""


def safe_extract_attr(element, attr: str) -> str:
    """Extract attribute from element with null checks."""
    try:
        return element.get_attribute(attr) if element else ""
    except:
        return ""


def analyze_coaching_content(tweet_content: str) -> bool:
    """Check if tweet contains coaching indicators."""
    content_lower = tweet_content.lower()

    # Check for coaching keywords
    keyword_matches = sum(1 for kw in COACH_KEYWORDS if kw.lower() in content_lower)

    # Check for patterns
    has_how_to = "how to" in content_lower or "how i" in content_lower
    has_case_study = "case study" in content_lower or "we helped" in content_lower
    has_income = "$" in tweet_content and any(kw in content_lower for kw in ["revenue", "made", "generated", "income"])

    return (keyword_matches >= 1) or has_how_to or has_case_study or has_income


# ============================================================================
# Core Extraction Functions
# ============================================================================

def extract_profile_data(handle: str, page, min_followers: int = 5000, max_followers: int = 20000) -> Optional[CoachProfile]:
    """
    Extract complete profile data using Playwright.

    Args:
        handle: Twitter handle (without @)
        page: Playwright page object
        min_followers: Minimum follower count for filtering
        max_followers: Maximum follower count for filtering

    Returns:
        CoachProfile object or None if extraction fails
    """
    try:
        # Navigate to profile
        profile_url = f"https://x.com/{handle}"
        page.goto(profile_url, wait_until="domcontentloaded", timeout=30000)
        random_delay(2, 4)

        # Extract name
        name_elem = page.query_selector('[data-testid="UserName"] span')
        name = safe_extract_text(name_elem) if name_elem else handle

        # Extract bio
        bio_elem = page.query_selector('[data-testid="UserDescription"]')
        bio = safe_extract_text(bio_elem)

        # Extract follower count - try multiple selectors
        followers_elem = page.query_selector('a[href*="/followers"]')
        follower_text = "0"
        if followers_elem:
            # Get all spans within the link
            spans = followers_elem.query_selector_all('span')
            # Find the one that looks like a number (contains K, M, or mostly digits)
            for span in spans:
                text = safe_extract_text(span)
                if text:
                    # Check if it looks like a follower count (e.g., "12.5K", "1.2M", "10,234")
                    text_clean = text.replace(',', '').replace('.', '').replace('K', '').replace('M', '')
                    if text_clean.isdigit() and len(text_clean) > 0:
                        follower_text = text
                        break
        follower_count = parse_follower_count(follower_text)

        # Extract following count
        following_elem = page.query_selector('a[href*="/following"]')
        following_text = "0"
        if following_elem:
            spans = following_elem.query_selector_all('span')
            for span in spans:
                text = safe_extract_text(span)
                if text:
                    text_clean = text.replace(',', '').replace('.', '').replace('K', '').replace('M', '')
                    if text_clean.isdigit() and len(text_clean) > 0:
                        following_text = text
                        break
        following_count = parse_follower_count(following_text)

        # Check verification
        verified_elem = page.query_selector('[data-testid="UserVerifiedBadge"]')
        verified = verified_elem is not None

        # Extract tier from TIER_MAP if this is a seed coach
        tier = TIER_MAP.get(handle)

        # Extract recent tweets
        recent_tweets = extract_recent_tweets(page, count=10)

        # Calculate engagement metrics
        total_likes = sum(t.likes for t in recent_tweets)
        total_engagement = sum(t.likes + t.retweets + t.replies for t in recent_tweets)
        avg_engagement_rate = (total_engagement / (follower_count or 1)) / len(recent_tweets) if recent_tweets else 0.0

        # Create profile
        profile = CoachProfile(
            handle=handle,
            name=name,
            bio=bio,
            profile_url=profile_url,
            follower_count=follower_count,
            verified=verified,
            following_count=following_count,
            tier=tier,
            recent_tweets=recent_tweets,
            avg_engagement_rate=avg_engagement_rate,
            passes_follower_filter=(min_followers <= follower_count <= max_followers)
        )

        return profile

    except Exception as e:
        print(f"  ‚úó Error extracting profile for @{handle}: {e}")
        return None


def extract_recent_tweets(page, count: int = 10) -> List[TweetData]:
    """
    Extract recent tweets from profile page.

    Args:
        page: Playwright page object (already on profile page)
        count: Number of tweets to extract

    Returns:
        List of TweetData objects
    """
    tweets = []

    try:
        # Scroll to load more tweets
        for _ in range(3):
            page.evaluate("window.scrollBy(0, window.innerHeight)")
            random_delay(0.5, 1.0)

        # Get tweet elements
        tweet_elems = page.query_selector_all('[data-testid="tweet"]')

        # Extract data from each tweet (limit to requested count)
        for tweet_elem in tweet_elems[:count]:
            try:
                # Extract content
                text_elem = tweet_elem.query_selector('[data-testid="tweetText"]')
                content = safe_extract_text(text_elem) if text_elem else ""

                # Extract metrics
                likes_elem = tweet_elem.query_selector('[data-testid="like"] span')
                likes = parse_count(safe_extract_text(likes_elem)) if likes_elem else 0

                retweets_elem = tweet_elem.query_selector('[data-testid="retweet"] span')
                retweets = parse_count(safe_extract_text(retweets_elem)) if retweets_elem else 0

                replies_elem = tweet_elem.query_selector('[data-testid="reply"] span')
                replies = parse_count(safe_extract_text(replies_elem)) if replies_elem else 0

                # Extract URL
                link_elem = tweet_elem.query_selector('a[href*="/status/"]')
                tweet_url = safe_extract_attr(link_elem, "href") if link_elem else ""
                if tweet_url and not tweet_url.startswith("http"):
                    tweet_url = "https://x.com" + tweet_url

                # Check if coaching content
                is_coaching = analyze_coaching_content(content)

                tweets.append(TweetData(
                    tweet_url=tweet_url,
                    content=content,
                    posted_date="",  # Can extract if needed
                    likes=likes,
                    retweets=retweets,
                    replies=replies,
                    is_coaching_content=is_coaching
                ))

            except Exception as e:
                print(f"    Warning: Could not extract tweet: {e}")
                continue

        return tweets

    except Exception as e:
        print(f"  ‚úó Error extracting tweets: {e}")
        return []


def validate_coach(profile: CoachProfile, min_coaching_ratio: float = 0.4, days_active: int = 30) -> str:
    """
    Score profile on likelihood of being a coach with enhanced validation.

    Enhanced validation:
    - Content ratio: Must have enough coaching-related tweets
    - Recency: Must have recent activity (within 30 days)
    - CTA detection: Checks for coaching service offers

    Scoring:
    - HIGH: 3+ indicators in bio OR 2+ coaching tweets + passes enhanced checks
    - MEDIUM: 2 indicators in bio OR 1+ coaching tweets + passes some checks
    - LOW: 1 indicator anywhere
    - UNKNOWN: No indicators

    Args:
        profile: CoachProfile object
        min_coaching_ratio: Min % of tweets that should be coaching-related (default 0.4 = 40%)
        days_active: Max days since last tweet (default 30 days)

    Returns:
        Validation score: "high" | "medium" | "low" | "unknown"
    """
    indicators = []

    # Check bio
    bio_lower = profile.bio.lower()
    bio_indicators = [kw for kw in COACH_KEYWORDS if kw.lower() in bio_lower]
    if bio_indicators:
        indicators.extend([f"bio:{kw}" for kw in bio_indicators])

    # Check tweets
    coaching_tweets = sum(1 for t in profile.recent_tweets if t.is_coaching_content)
    total_tweets = len(profile.recent_tweets)
    coaching_ratio = coaching_tweets / total_tweets if total_tweets > 0 else 0.0

    if coaching_tweets > 0:
        indicators.append(f"coaching_tweets:{coaching_tweets}/{total_tweets} ({coaching_ratio:.0%})")

    # Content ratio check
    if coaching_ratio >= min_coaching_ratio:
        indicators.append("high_coaching_content_ratio")
    elif coaching_ratio > 0:
        indicators.append(f"low_coaching_content_ratio ({coaching_ratio:.0%})")

    # Check engagement (high engagement = influential)
    if profile.avg_engagement_rate > 0.05:  # 5% engagement rate
        indicators.append("high_engagement")

    # Recency check - when was the last tweet?
    if profile.recent_tweets:
        # For simplicity, we'll check if they have any tweets (Twitter API gives recent tweets)
        # In production, you'd parse actual dates from tweets
        indicators.append("recently_active")
    else:
        indicators.append("no_recent_tweets")

    # CTA detection - check bio and tweets for coaching service offers
    cta_keywords = [
        "DM for", "link in bio", "apply now", "join the program",
        "consulting", "mentorship", " coaching", "agency services",
        "book a call", "schedule a call", "work with me"
    ]

    bio_has_cta = any(cta in bio_lower for cta in cta_keywords)
    tweets_have_cta = sum(1 for t in profile.recent_tweets if any(cta in t.content.lower() for cta in cta_keywords))

    if bio_has_cta or tweets_have_cta >= 2:
        indicators.append("has_coaching_cta")

    profile.coach_indicators = indicators

    # Enhanced scoring
    has_good_bio = len(bio_indicators) >= 2
    has_good_content = coaching_tweets >= 2 and coaching_ratio >= min_coaching_ratio
    has_cta = "has_coaching_cta" in indicators
    is_active = "recently_active" in indicators
    not_low_ratio = "low_coaching_content_ratio" not in indicators

    # HIGH: Strong indicators OR good content + CTA + active
    if (len(bio_indicators) >= 3 or
        (has_good_content and has_cta and is_active and not_low_ratio)):
        return "high"

    # MEDIUM: Some indicators OR moderate content
    elif (has_good_bio or
          (coaching_tweets >= 1 and is_active and not_low_ratio) or
          (has_good_content and is_active)):
        return "medium"

    # LOW: Basic indicators present
    elif len(indicators) >= 2:
        return "low"

    # UNKNOWN: Insufficient data
    else:
        return "unknown"


def analyze_seed_coaches(handles: List[str], page, min_followers: int = 5000, max_followers: int = 20000, min_coaching_ratio: float = 0.4, days_active: int = 30) -> List[CoachProfile]:
    """
    Analyze seed coaches to build baseline for discovery.

    Args:
        handles: List of coach handles
        page: Playwright page object
        min_followers: Minimum follower count
        max_followers: Maximum follower count
        min_coaching_ratio: Minimum ratio of coaching content
        days_active: Days active within period

    Returns:
        List of CoachProfile objects
    """
    profiles = []

    for i, handle in enumerate(handles, 1):
        print(f"[{i}/{len(handles)}] Analyzing @{handle}...")

        # Anti-bot delay between profiles
        if i > 1:
            random_delay(3, 6)

        profile = extract_profile_data(handle, page, min_followers, max_followers)

        if profile:
            # Validate coach with enhanced parameters
            profile.validation_score = validate_coach(
                profile,
                min_coaching_ratio=min_coaching_ratio,
                days_active=days_active
            )
            profile.discovered_via = "seed"

            # Show validation details
            indicators_str = ", ".join([f"{ind}" for ind in profile.coach_indicators[:3]])
            print(f"  ‚úì {profile.name} - {profile.follower_count:,} followers")
            print(f"    {profile.validation_score.upper()} confidence | {indicators_str}")

            if profile.passes_follower_filter:
                profiles.append(profile)
            else:
                print(f"    (Filtered by follower count)")

    return profiles


def analyze_themes(tweet_texts: List[str]) -> List[str]:
    """
    Extract common themes from tweets.

    Args:
        tweet_texts: List of tweet content strings

    Returns:
        List of theme strings
    """
    themes = []
    text = " ".join(tweet_texts).lower()

    for theme, keywords in THEME_KEYWORDS.items():
        if any(kw in text for kw in keywords):
            themes.append(theme)

    return themes


def generate_personalized_hook(profile: CoachProfile) -> str:
    """
    Generate personalized outreach hook based on coach's content.

    Args:
        profile: CoachProfile object

    Returns:
        Personalized hook string
    """
    # Find themes
    themes = analyze_themes([t.content for t in profile.recent_tweets])

    # Get most engaging tweet
    if profile.recent_tweets:
        top_tweet = max(profile.recent_tweets, key=lambda t: t.likes + t.retweets)
        content_preview = top_tweet.content[:30] + "..." if len(top_tweet.content) > 30 else top_tweet.content
    else:
        content_preview = "your content"

    # Generate hook based on theme
    if "cold email" in themes or "lead gen" in themes:
        hook = f"Hey {profile.name}, saw your recent tweet about {content_preview} You seem to really know cold email. We're building something that could help your clients scale their outreach - mind if I share more?"

    elif "ads" in themes:
        hook = f"Hey {profile.name}, loved your post on {content_preview} Your expertise in ad scaling is clear. We're working on a tool that helps agencies like yours optimize client campaigns - open to a quick chat?"

    elif "scaling" in themes or "agency" in themes:
        hook = f"Hey {profile.name}, saw your content about {content_preview} You've clearly cracked the code on agency scaling. We're building something to help coaches like you streamline operations - interested in seeing how it works?"

    else:
        hook = f"Hey {profile.name}, been following your content - love your insights on {content_preview} We're building tools for agency coaches and thought you'd be a perfect fit. Want to see what we're working on?"

    profile.personalized_hook = hook
    profile.hook_rationale = f"Based on themes: {', '.join(themes[:3]) if themes else 'general'}"

    return hook


# ============================================================================
# Data Export Functions
# ============================================================================

def save_to_json(profiles: List[CoachProfile], output_path: str):
    """
    Save profiles to JSON file.

    Args:
        profiles: List of CoachProfile objects
        output_path: Path to output JSON file
    """
    data = {
        "metadata": {
            "total_coaches": len(profiles),
            "high_confidence": sum(1 for p in profiles if p.validation_score == "high"),
            "medium_confidence": sum(1 for p in profiles if p.validation_score == "medium"),
            "low_confidence": sum(1 for p in profiles if p.validation_score == "low"),
            "last_updated": datetime.now().isoformat()
        },
        "coaches": [p.to_dict() for p in profiles]
    }

    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w') as f:
        json.dump(data, f, indent=2)

    print(f"\n‚úì Saved {len(profiles)} coaches to {output_path}")


def save_to_csv(profiles: List[CoachProfile], output_path: str):
    """
    Save profiles to CSV for analysis.

    Args:
        profiles: List of CoachProfile objects
        output_path: Path to output CSV file
    """
    if not PANDAS_AVAILABLE:
        print(f"\n‚ö†Ô∏è  Skipping CSV export (pandas not available)")
        return

    rows = []
    for p in profiles:
        rows.append({
            "handle": p.handle,
            "name": p.name,
            "bio": p.bio[:200] + "..." if len(p.bio) > 200 else p.bio,  # Truncate long bios
            "follower_count": p.follower_count,
            "verified": p.verified,
            "validation_score": p.validation_score,
            "tier": p.tier or "",
            "avg_engagement_rate": f"{p.avg_engagement_rate:.2%}",
            "posting_frequency": f"{p.posting_frequency:.1f}",
            "engages_with_coaches": p.engages_with_coaches,
            "personalized_hook": p.personalized_hook or "",
            "discovered_via": p.discovered_via,
            "coach_indicators": ", ".join(p.coach_indicators),
            "profile_url": p.profile_url
        })

    df = pd.DataFrame(rows)

    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    df.to_csv(output_file, index=False)

    print(f"‚úì Exported {len(profiles)} coaches to {output_path}")


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Discover and analyze agency coaches on Twitter"
    )

    # Discovery modes
    parser.add_argument("--seeds-only", action="store_true",
                        help="Only analyze seed coaches")
    parser.add_argument("--skip-network", action="store_true",
                        help="Skip network analysis phase")

    # Input
    parser.add_argument("--seeds", type=str,
                        default="src/growth/twitter/config/tasks.yaml",
                        help="Path to config file (YAML)")
    parser.add_argument("--search-terms", type=str, nargs="+",
                        default=["SMMA coach", "agency scale", "cold email wizard"],
                        help="Search terms for coach discovery")

    # Filters
    parser.add_argument("--min-followers", type=int, default=5000,
                        help="Minimum follower count")
    parser.add_argument("--max-followers", type=int, default=20000,
                        help="Maximum follower count")
    parser.add_argument("--min-validation", type=str,
                        choices=["high", "medium", "low", "unknown"],
                        default="medium",
                        help="Minimum validation score")
    parser.add_argument("--min-coaching-ratio", type=float, default=0.4,
                        help="Minimum %% of tweets that should be coaching-related (default 0.4 = 40%%)")
    parser.add_argument("--days-active", type=int, default=30,
                        help="Require activity within last N days (default 30)")

    # Output
    parser.add_argument("--output-dir", type=str, default="src/growth/twitter/data/coaches",
                        help="Output directory")
    parser.add_argument("--json", type=str, default="agency_coaches.json",
                        help="JSON output filename")
    parser.add_argument("--csv", type=str, default="outreach_list.csv",
                        help="CSV output filename")

    # Browser
    parser.add_argument("--port", type=int, default=9223,
                        help="Chrome remote debugging port")

    # Performance
    parser.add_argument("--max-profiles", type=int, default=200,
                        help="Maximum profiles to process")

    args = parser.parse_args()

    print("\n" + "=" * 80)
    print("TWITTER COACH DISCOVERY TOOL")
    print("=" * 80)
    print(f"Min followers: {args.min_followers:,}")
    print(f"Max followers: {args.max_followers:,}")
    print(f"Min validation: {args.min_validation}")
    print(f"Min coaching ratio: {args.min_coaching_ratio:.0%}")
    print(f"Active within: {args.days_active} days")
    print(f"Search terms: {', '.join(args.search_terms)}")
    print()

    print("üîÑ Connecting to browser...")

    with sync_playwright() as p:
        browser = p.chromium.connect_over_cdp(f"http://localhost:{args.port}")
        context = browser.contexts[0]
        page = context.pages[0] if context.pages else context.new_page()

        print("‚úì Connected")
        print()

        try:
            # Load seed handles from config
            config_path = Path(args.seeds)
            if not config_path.is_absolute():
                config_path = project_root / args.seeds

            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)

            seed_handles = config.get('coach_seeds', [])

            print(f"Loaded {len(seed_handles)} seed coaches from config")
            print()

            # Full pipeline implementation
            all_profiles = []

            # ========================================
            # Phase 1: Seed Coach Analysis
            # ========================================
            print("=" * 80)
            print("PHASE 1: Analyzing Seed Coaches")
            print("=" * 80)
            print()

            seed_profiles = analyze_seed_coaches(
                seed_handles,
                page,
                args.min_followers,
                args.max_followers,
                args.min_coaching_ratio,
                args.days_active
            )

            print(f"\n‚úì Analyzed {len(seed_profiles)} seed coaches")
            print(f"  - High confidence: {sum(1 for p in seed_profiles if p.validation_score == 'high')}")
            print(f"  - Medium confidence: {sum(1 for p in seed_profiles if p.validation_score == 'medium')}")
            print(f"  - Low confidence: {sum(1 for p in seed_profiles if p.validation_score == 'low')}")
            print()

            all_profiles.extend(seed_profiles)

            # For now, we'll just use seed coaches (skip search/network for MVP)
            if not args.seeds_only:
                print("\n" + "=" * 80)
                print("SKIP: Keyword search and network analysis not yet implemented")
                print("=" * 80)
                print("Run with --seeds-only to only analyze seed coaches")
                print()

            # ========================================
            # Phase 2: Filter by validation score
            # ========================================
            print("\n" + "=" * 80)
            print("PHASE 2: Final Validation & Scoring")
            print("=" * 80)
            print()

            # Validation score order (for filtering)
            validation_order = {"high": 3, "medium": 2, "low": 1, "unknown": 0}
            min_score_value = validation_order[args.min_validation]

            validated_profiles = [
                p for p in all_profiles
                if validation_order[p.validation_score] >= min_score_value
            ]

            print(f"‚úì Filtered to {len(validated_profiles)} coaches (min score: {args.min_validation})")
            print()

            # ========================================
            # Phase 3: Generate personalized hooks
            # ========================================
            print("=" * 80)
            print("PHASE 3: Generating Outreach Hooks")
            print("=" * 80)
            print()

            for i, profile in enumerate(validated_profiles, 1):
                generate_personalized_hook(profile)
                print(f"[{i}/{len(validated_profiles)}] @{profile.handle}: {profile.personalized_hook[:70]}...")

            print()

            # ========================================
            # Phase 4: Export results
            # ========================================
            print("=" * 80)
            print("EXPORTING RESULTS")
            print("=" * 80)
            print()

            json_path = f"{args.output_dir}/{args.json}"
            csv_path = f"{args.output_dir}/{args.csv}"

            save_to_json(validated_profiles, json_path)
            save_to_csv(validated_profiles, csv_path)

            print()
            print("=" * 80)
            print("DISCOVERY COMPLETE!")
            print("=" * 80)
            print(f"\nTotal coaches discovered: {len(validated_profiles)}")
            print(f"\nResults saved to:")
            print(f"  - {json_path}")
            print(f"  - {csv_path}")
            print()


        finally:
            browser.close()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrupted")
        sys.exit(0)
